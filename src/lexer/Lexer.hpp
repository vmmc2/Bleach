#pragma once

#include <any>
#include <map>
#include <string>
#include <string_view>
#include <utility>
#include <vector>

#include "../error/Error.hpp"
#include "../utils/Token.hpp"


/**
 * @class Lexer
 * @brief Performs the lexical analysis stage of the Bleach Interpreter.
 *
 * The Lexer class is responsible for scanning the contents of the source code from a Bleach file
 * (which is represented as a string) and breaking it down into a series of tokens that can be used
 * by the parser later on. It handles various aspects of lexical analysis, including recognizing 
 * keywords, identifiers, literals, and operators.
 *
 * @note The lexer assumes that the input is syntactically valid up to the point of lexical analysis
 * and does not handle syntax errors beyond tokenization.
 */
class Lexer{
  private:
    std::string_view sourceCode; /**< Variable that represents the source code written inside a Bleach file, which the Lexer will lex. */
    std::vector<Token> tokens; /**< Variable that represents the list of tokens that will be generated after the lexical analysis is done by the Lexer. */
    int start = 0; /**< Variable that points to the first/start character of the lexeme that is being consumed (This index is in relation to the 'sourceCode' variable). */
    int current = 0; /**< Variable that points to the character that is the next one to be consumed by the lexer. */
    int line = 1; /**< Variable that holds the information about which line the lexer is currently at with respect to the source code file. It helps the lexer to generate tokens that know their location in the source code file. */

    /**
     * @brief Signals whether the lexer has reached the end of the source code file or not.
     *
     * This method checks whether the 'current' variable value is equal or bigger than the length
     * of the string present inside the 'sourceCode' variable. If that's the case, then it means the
     * lexer has reached the end of the source code file and, thus, the lexical analysis is finished
     * and the sequence of tokens with respect to the given program has been generated. Otherwise, it
     * means the lexical analysis needs to keep going.
     * 
     * @return A boolean that signals whether the lexer has reached the end of the string of the
     * source code or not.
     */
    bool isAtEnd(){
      return current >= sourceCode.length();
    }

    /**
     * @brief Consumes the next unconsumed character in the source code file and returns it.
     * 
     * This method is responsible for consuming the character pointed by the 'current' variable
     * (which is the next unconsumed character), increments 'current' by 1 and returns this character
     * that was just consumed.
     * 
     * @return A char that is the latest character that has been just consumed by the lexer.
    **/
    char advance(){
      current++;

      return sourceCode[current - 1];
    }

    /**
     * @brief Based on the latest consumed lexeme, creates its token and inserts it into the sequence of
     * token ('tokens' variable) that is being generated by the lexer.
     * 
     * This method is responsible for creating a new token and inserting into the 'tokens' variable,
     * which is the sequence of tokens that will be generated by the lexer during the process of lexical analysis.
     * Such method creates the new token based on the latest consumed lexeme, along with its literal value, its 
     * token type and the line that such lexeme appears in the source code file.
     * 
     * @param type The type of the token (based on the TokenType enum) that is about to be generated by the 
     * lexer.
     * @param literal The living runtime object related to the lexeme that has been just consumed and its 
     * about to be used to generate the next token by the lexer.
     * 
     * @return Nothing (void).
    **/
    void addToken(TokenType type, std::any literal){
      std::string lexeme{sourceCode.substr(start, current - start)}; // To understand how and why this works, pay attention to the flow of the lexing process.
      tokens.emplace_back(Token(type, std::move(lexeme), std::move(literal), line));

      return;
    }

    /**
     * @brief Indirectly creates a token, whose literal value is guaranteed to be null, and inserting
     * into the sequence of tokens.
     * 
     * This method, based on the latest consumed lexeme (which is guaranteed to be a token whose literal 
     * object is nullptr), is responsible for calling the method that actually creates such token and 
     * inserts it at the end of the 'tokens' variable.
     * 
     * @param type The type of the token (based on the TokenType enum) that is about to be generated by the 
     * lexer.
     * 
     * @return Nothing (void).
    **/
    void addToken(TokenType type){
      addToken(type, nullptr);

      return;
    }

    /**
     * @brief Works like a conditional version of the 'advance' method from this same class.
     * 
     * This method is responsible for working like a conditional 'advance' method. It receives an expected
     * character and checks whether the next unconsumed character by the lexer (the one pointed by the variable
     * 'current') is equal to the expected one. If that's the case, then the character pointed by 'current' is
     * also consumed. Otherwise, it's not consumed.
     * 
     * @param expected A char that represents the next character expected to be consumed by the lexer (the one
     * currently being pointed by the 'current' variable).
     * 
     * @return A boolean that signals whether the expected character was consumed by the lexer or not.
    **/
    bool match(char expected){
      if(isAtEnd()){
        return false;
      }
      if(sourceCode[current] != expected){
        return false;
      }
      current++;

      return true;
    }

    /**
     * @brief Works like the 'advance' method. However, it doesn't consume the next character yet
     * to be consumed by the lexer.
     * 
     * This method is responsible for returning the next character yet to be consumed by the lexer. In other
     * words, this method returns the character that the 'current' variable currently points to.
     * 
     * @return The char that is being currently being pointed by the 'current' variable. That is, the next char
     * that has not been consumed by the lexer yet.
     * 
     * @note If the lexer has reached the end of the 'sourceCode' string variable, then it returns the '\0' character.
    **/
    char peek(){
      if(isAtEnd()){
        return '\0';
      }

      return sourceCode[current];
    }

    /**
     * @brief 
     * 
     * This method
     * 
     * @return Nothing (void).
    **/
    void lexToken(){
      char c = advance();
      switch(c){
        case('('):
          addToken(TokenType::LEFT_PAREN);
          break;
        case(')'):
          addToken(TokenType::RIGHT_PAREN);
          break;
        case('['):
          addToken(TokenType::LEFT_BRACKET);
          break;
        case(']'):
          addToken(TokenType::RIGHT_BRACKET);
          break;
        case('{'):
          addToken(TokenType::LEFT_BRACE);
          break;
        case('}'):
          addToken(TokenType::RIGHT_BRACE);
          break;
        case(','):
          addToken(TokenType::COMMA);
          break;
        case('.'):
          addToken(TokenType::DOT);
          break;
        case('?'):
          addToken(TokenType::QUESTION_MARK);
          break;
        case(':'):
          addToken(TokenType::COLON);
          break;
        case(';'):
          addToken(TokenType::SEMICOLON);
          break;
        case('+'):
          addToken(TokenType::PLUS);
          break;
        case('-'):
          addToken(TokenType::MINUS);
          break;
        case('*'):
          addToken(TokenType::STAR);
          break;
        case('/'):
          if(match('/')){ // Single-Line comment.
            while(peek() != '\n' && !isAtEnd()) advance();
          }else if(match('*')){ // Multi-Line comment.

          }else{ // Division operator.
            addToken(TokenType::SLASH);
          }
          break;
        case('!'):
          addToken(match('=') ? TokenType::BANG_EQUAL : TokenType::BANG);
          break;
        case('='):
          addToken(match('=') ? TokenType::EQUAL_EQUAL : TokenType::EQUAL);
          break;
        case('>'):
          addToken(match('=') ? TokenType::GREATER_EQUAL : TokenType::GREATER);
          break;
        case('<'):
          addToken(match('=') ? TokenType::LESS_EQUAL : TokenType::LESS);
          break;
        case(' '):
        case('\r'):
        case('\t'):
          break; // The lexer ignore whitespace characters.
        case('\n'):
          line++;
          break;
        default:
          error(line, "Unexpected character not supported by the Bleach language: " + c);
          break;
      }

      return;
    }

  public:
    /**
     * @brief Constructs a Lexer with the source code (as a string) present inside a Bleach (.bah) file. 
     *
     * This constructor initializes a Lexer object with the given source code of a Bleach file,
     * represented as a string.
     *
     * @param sourceCode The source code of the Bleach file intended to be interpreted. Such source code is 
     * provided as a string.
     *
     * @note The sourceCode parameter is moved into the Lexer object to avoid unnecessary copies.
     */
    Lexer(std::string_view sourceCode)
      : sourceCode{std::move(sourceCode)}
    {}

    /**
     * @brief Performs the lexical analysis on the string present inside the 'sourceCode' variable
     * and returns a list of all tokens generated by the execution of such analysis.
     * 
     * This method is responsible for performing the lexical analysis on the string that resides inside
     * the 'sourceCode' variable. The lexical analysis is responsible for performing a linear scan on
     * such string and group the characters of the string into sequences of characters that have a meaning.
     * These sequence of characters are called lexemes and with them and other information it creates tokens.
     * When the lexical analysis reaches the end of the string, a sequence of tokens is generated and returned
     * by this method.
     * 
     * @return The list of tokens (std::vector<Token>) generated by the lexical analysis.
    **/
    std::vector<Token> lexTokens(){
      while(!isAtEnd()){ // The lexer is at the beginning of the next lexeme to be built.
        start = current;
        lexToken();
      }
      tokens.emplace_back(Token(TokenType::FILE_END, "", nullptr, line)); // For easiness purposes, the lexer always adds a 'FILE_END' token as the last token in the sequence of tokens to signal the end of the program.

      return tokens;
    }
};
